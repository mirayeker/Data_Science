# Feature Engineering

---

### Feature Engineering : Ã–zellikler Ã¼zerinde gerÃ§ekleÅŸtirilen Ã§alÄ±ÅŸmalar

### Data Pre-Processing: Ã‡alÄ±ÅŸmalar Ã¶ncesi verinin uyun hale getirilmesi sÃ¼recidir.

<aside>
ğŸ’¡ If Your Data Is Bad, Your Machine Learning Tools Are Useless ğŸ™‚

</aside>

<aside>
ğŸ’¡ Applied machine learning is basically feature engineering - Andrew Ng

</aside>

---

## Outliers (AykÄ±rÄ± DeÄŸerler)

Verideki genel eÄŸilmin oldukÃ§a dÄ±ÅŸÄ±naa Ã§Ä±kan deÄŸerlere denir.

! Ã–zellikle doÄŸrusal problemlerde aykÄ±rÄ± deÄŸerlerin etkisi daha ÅŸiddetli olur. (AÄŸaÃ§ yÃ¶ntemlerinde daha azdÄ±r.)

### AykÄ±rÄ± DeÄŸerler Neye gÃ¶re belirlenir.

- SektÃ¶r Bilgisi
- Standart SApma YaklaÅŸÄ±mÄ±
- Z-Skoru yaklaÅŸÄ±mÄ±
- Boxplot (interquartile range- IQR) yÃ¶ntemi â†’ Tek deÄŸiÅŸkenli olarak
- LOF â†’ Ã§ok deÄŸiÅŸkenli olarak

### AykÄ±rÄ± DeÄŸer Problemlerini Ã‡Ã¶zme:

- BaskÄ±lama YÃ¶ntemi (re-assigment with threshold): Alt ve Ã¼st sÄ±nÄ±rlarÄ±n deÄŸerini aykÄ±rÄ± deÄŸere atar. (Replace eder.)
- Ã‡ok DeÄŸiÅŸkenli AykÄ±rÄ± DeÄŸer Analizi (Local outlier Factor): Tek baÅŸÄ±na aykÄ±rÄ± olmayacak deÄŸerler birlikte ele alÄ±ndÄ±ÄŸÄ±nda aykÄ±rÄ± olabilir. (Mesela 17 yaÅŸÄ±nda birinin 3 defa evlenmesi)
    - LOF : GÃ¶zlemleri bulunduklarÄ± konumun yoÄŸunluk tabanlÄ± skorlayarak aykÄ±rÄ± deÄŸerlere ulaÅŸmamÄ±zÄ± saÄŸlar.
    - A noktasÄ± aÃ§Ä±kca gÃ¶rÃ¼nÃ¼yor ki komÅŸularÄ±na oldukÃ§a uzaktÄ±r. Bu sebeple aykÄ±rÄ± deÄŸer diyebiliriz.
        
        ![Untitled](Feature%20Engineering%20c9372051bc35473fb5cadfb222dc0776/Untitled.png)
        
    - Peki LOF ile yakaladÄ±ÄŸÄ±mÄ±z deÄŸerleri nasÄ±l handle edebiliriz?
        - Yakalanan deÄŸerlerin boyutu kÃ¼Ã§Ã¼kse silebilirz ama bÃ¼yÃ¼kse ?
        - BaskÄ±lama yÃ¶ntemi ile doldurabiliriz ama hangi deÄŸerle dolduracaÄŸÄ±z bir tane gÃ¶zlem birimiyle doldursak duplicate problemi oluÅŸacak ve veride gÃ¼rÃ¼ltÃ¼ oluÅŸturacaÄŸÄ±z ?
        
        <aside>
        ğŸ’¡ AÄŸaÃ§ yÃ¶ntemi ile Ã§alÄ±ÅŸÄ±yorsak aykÄ±rÄ± deÄŸerlere hiÃ§ dokunmak tercih edilebilir. EÄŸer probleme gÃ¶re bunlar gÃ¶z ardÄ± edilmemesi gerekiyorsa, IQR yÃ¶ntemi ile tÃ¼m deÄŸiÅŸkenlere ufak bir dokunabiliriz.
        
        </aside>
        
        <aside>
        ğŸ’¡ Peki ya DoÄŸrusal yÃ¶ntemler kullanÄ±yorsak? O zaman aykÄ±rÄ± deÄŸerler ciddi bir problemdir, aykÄ±rÄ± deÄŸerleri doldurmaktan ziyade  az ise silinebilir, doldurak yerine de baskÄ±lama yÃ¶ntemi tercih edilebilir.
        
        </aside>
        
        > GÃ¶zlem sayÄ±sÄ± Ã§ok olduÄŸunda baskÄ±lama yÃ¶ntemi kullanmak Ã§ok mantÄ±klÄ± olmayacaktÄ±r, gÃ¶zlem sayÄ±sÄ± az ise LOF ile bakÄ±ldÄ±ktan sonra o aykÄ±rÄ± deÄŸerler Ã§Ä±karÄ±lmalÄ±dÄ±r.
        > 
        

 

---

## Missing Values (Eksik DeÄŸerler)

GÃ¶zlemlerde eksiklik olmasÄ± durumunu ifade etmektedir.

Eksik Veri Problemi NasÄ±l Ã‡Ã¶zÃ¼lÃ¼r?

- Silme
- DeÄŸer Atama YÃ¶ntemleri (Basit Atama YÃ¶ntemleri, ortalama, median gibi deÄŸerler atanÄ±r.)
- Tahmine DayalÄ± YÃ¶ntemler (Makine Ã¶ÄŸrenmesi veya istatistiksel yÃ¶ntemlere dayanÄ±r.)

Eksik veride dikkat edilmesi gereken nokta: EKSÄ°K VERÄ°NÄ°N RASSALLIÄININ Ä°NCELENMESÄ°

> Eksik verinin rassallÄ±ÄŸÄ±nÄ± incelemek, eksik deÄŸerlerin oluÅŸma sebeplerini anlamak ve veri setindeki eksikliklerin sistematik bir dÃ¼zeni olup olmadÄ±ÄŸÄ±nÄ± belirlemek amacÄ±yla yapÄ±lÄ±r. (Ã–rnneÄŸi bir kredi kartÄ± analizi yapÄ±lacak, ve bir bireyin hiÃ§ kredi kartÄ± yok bu durumda gÃ¶zlem birimi nullâ€™dÄ±r, bu null deÄŸer doldurulmamalÄ±dÄ±r!! )
> 

### Eksik DeÄŸer Problemini Ã‡Ã¶zme

TÄ±pkÄ± aykÄ±rÄ± deÄŸer probleminde olduÄŸu gibi, eÄŸer aÄŸaca dayalÄ± yÃ¶ntemler kullanÄ±lÄ±yorsa, bu durumda missing valueâ€™lar gÃ¶z ardÄ± edilebilir.

! Kategorik deÄŸiÅŸkenler iÃ§in yapÄ±labilecek en mantÄ±klÄ± yaklaÅŸÄ±m modu ile doldurmaktÄ±r.

- Tahmine DayalÄ± YÃ¶ntemlerde Bir modelleme tekniÄŸi kullanÄ±lacaÄŸÄ± iÃ§in dikkat edilmesi gereken noktalar:
    1. Kategorik deÄŸiÅŸkenlerin one-hot ya da label  encoder uygulanmasÄ± gerekir.
    2. KNN uygulayacaÄŸÄ±mÄ±z iÃ§in verilerin standartlaÅŸtÄ±rÄ±lmasÄ± gerekir. 

---

## Encoding

DeÄŸiÅŸkenlerin temsil ÅŸekillerinin deÄŸiÅŸtirilmesi

### Label Encoding:

Elimizdeki kategorik (nominal veya ordinal) deÄŸiÅŸkenleri sayÄ±sal deÄŸerler ile temsil etmektir. (Mesela cinsiyet: kadÄ±n, erkek â†’ kadÄ±n:0, erkek:1)

> **Nominal Veriler:** Nominal veriler, sÄ±ralÄ± bir yapÄ±sÄ± olmayan verilerdir. Ã–rneÄŸin, Ã¼lkelerin isimleri (TÃ¼rkiye, Fransa, Ä°ngiltere) nominal verilere Ã¶rnektir. Label encoding bu durumda uygun deÄŸildir, Ã§Ã¼nkÃ¼ bu verilerin sÄ±ralÄ± bir yapÄ±sÄ± yoktur. (Bu durumda one- hot encoding ile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi daha uygundur.)
> 

```jsx
nunique() -> fonskiyonu nan deÄŸerleri bir sÄ±nÄ±f olarak gÃ¶rmez.
unique() -> fonksiyonu ise nan deÄŸerleri de bir sÄ±nÄ±f olarak gÃ¶rÃ¼r. 
```

### One Hot Encoding

One-hot encoding, kategorik verileri sayÄ±sal forma dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lan bir kodlama tekniÄŸidir. Bu yÃ¶ntem, her bir kategoriye ayrÄ± bir sÃ¼tun atayarak, o kategorinin varlÄ±ÄŸÄ±nÄ± 1, yokluÄŸunu ise 0 ile temsil eder. (! KullanÄ±lmasÄ±nÄ±n asÄ±l nedeni, sÄ±nÄ±flar arasÄ±nda bir fark yoksa mesela; TÃ¼rkiye, Fransa, Ä°talya arasÄ±nda bir Ã¼stÃ¼nlÃ¼k farkÄ± yoktur biz bunlarÄ± 1,2,3 diye verirsek model oluÅŸtururken hataya sebebiyet verebiliriz.)

- Nominal veriler (sÄ±ralÄ± olmayan kategorik veriler) iÃ§in uygundur.
- Dikkat edilmesi gereken bir konu vardÄ±r:  Dummy DeÄŸiÅŸken TuzaÄŸÄ±:
    - Dummy deÄŸiÅŸken tuzaÄŸÄ±, one-hot encoding sÄ±rasÄ±nda ortaya Ã§Ä±kabilen bir durumdur. Bu durum, kategorik deÄŸiÅŸkenlerin birbirine baÄŸÄ±mlÄ± hale gelmesi sonucu oluÅŸur. Ã–zellikle, eÄŸer bir kategori, diÄŸer kategorilerin toplamÄ±yla ifade edilebiliyorsa, bu durum dummy deÄŸiÅŸken tuzaÄŸÄ±na neden olur.
    - Ã‡Ã¶zÃ¼mÃ¼ ise **drop_first = True** yapÄ±larak ilk sÄ±nÄ±f drop edilir ve deÄŸiÅŸkenlerin birbiri Ã¼zerinden oluÅŸmasÄ±(baÄŸÄ±mlÄ±lÄ±) engellenir.
    - get_dummies() fonksiyonu ile one-hot encoding oluÅŸturulur.

### Rare Encoding

Rare encoding, nadir gÃ¶rÃ¼len kategorik deÄŸerleri bir araya getirerek, veri setindeki dengesizlikleri azaltmak iÃ§in kullanÄ±lan bir kodlama tekniÄŸidir. Bu yÃ¶ntem, Ã¶zellikle kategorik deÄŸiÅŸkenlerin birÃ§ok farklÄ± deÄŸer iÃ§erdiÄŸi durumlarda kullanÄ±lÄ±r.

Rare encoding aÅŸaÄŸÄ±daki adÄ±mlarla gerÃ§ekleÅŸtirilir:

1. **Kategorik DeÄŸer FrekanslarÄ±na Bakma:** Ã–ncelikle, kategorik deÄŸiÅŸkenin deÄŸerlerinin frekanslarÄ±nÄ± kontrol ederiz. Nadir gÃ¶rÃ¼len deÄŸerler tespit edilir.
2. **Nadir GÃ¶rÃ¼len DeÄŸerleri Bir Araya Getirme:** Belirli bir eÅŸiÄŸin altÄ±nda olan (Ã¶rneÄŸin, 5 kez veya daha az tekrarlanan) kategorik deÄŸerler bir "Rare" kategorisine atanÄ±r.

Rare encoding'in avantajlarÄ± ÅŸunlar olabilir:

1. Veri setindeki dengesizliÄŸi azaltÄ±r.
2. Modelin nadir gÃ¶rÃ¼len kategorilere aÅŸÄ±rÄ± uyum (overfitting) yapmasÄ±nÄ± Ã¶nler.

### Feature Scaling (Ã–zellik Ã–lÃ§eklendirme)

Ã–zellik Ã¶lÃ§eklendirme amaÃ§larÄ±: 

1. DeÄŸiÅŸkenler arasÄ±ndaki Ã¶lÃ§Ã¼m farklÄ±lÄ±ÄŸÄ±nÄ± gidermektir. Kulanacak modellerin,deÄŸiÅŸkenlere eÅŸit ÅŸartlar altÄ±nda yaklaÅŸmasÄ±nÄ± saÄŸlamaktÄ±r.
2. Gradient descent kullanÄ±lan algoritmalarÄ±n, train sÃ¼relerini azaltma durumudur. (UzaklÄ±k temelli yÃ¶ntemlerde yanlÄ±lÄ±ÄŸÄ±n Ã¶nÃ¼ne geÃ§mektir.) (AÄŸaca dayalÄ± yÃ¶ntemlerde gÃ¶z ardÄ± edilebilir. )

**StandardScaler:** Klasik standartlaÅŸtÄ±rma. OrtalamayÄ± Ã§Ä±kar, standart sapmaya bÃ¶l. z = (x - u) / s

**RobustScaler:** MedyanÄ± Ã§Ä±kar iqr'a bÃ¶l (AykÄ±rÄ± deÄŸerlere gÃ¶re daha dayanÄ±klÄ±dÄ±r.)

**MinMaxScaler:** Verilen 2 deÄŸer arasÄ±nda deÄŸiÅŸken dÃ¶nÃ¼ÅŸÃ¼mÃ¼

---

## Feature Extraction (Ã–zellik Ã‡Ä±karÄ±mÄ±)

Ham veriden deÄŸÅŸken Ã¼retmek. 

1. YapÄ±sal Verilerden deÄŸiÅŸken Ã¼retmek â†’ (Elimizde zaten var olan verilerden yeni bir Ã¶zellik Ã¼retmek.)
2. YapÄ±sal Olmayan Verilerden deÄŸiÅŸken Ã¼retmek (GÃ¶rÃ¼ntÃ¼, ses gibi verilerden Ã¶zellik Ã¼retmek.)

## Feature interactions (Ã–zellik EtkileÅŸimleri)